{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TimesNet 教程\n",
    "**安装说明：** 本笔记本演示了 `TimesNet` 支持的学习任务。\n",
    "#\n",
    "`TimesNet` 基本上支持五类任务，分别是：长期预测、短期预测、缺失值填补、异常检测、分类。\n"
   ],
   "id": "c6743d3c66fdd06a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. 安装 Python 3.8。为了方便，执行以下命令。",
   "id": "cbe0f441e751514a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pip\n",
    "install - r\n",
    "requirements.txt\n"
   ],
   "id": "b4ce4e2681e9991f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. 导入包",
   "id": "dee230aae448ef52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "from layers.Embed import DataEmbedding\n",
    "from layers.Conv_Blocks import Inception_Block_V1\n",
    "\n",
    "\n",
    "# 用于对二维时序数据进行卷积的卷积块，可根据需要更换\n"
   ],
   "id": "4a6838e307efa095"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. TimesBlock 构建\n",
    " `TimesNet` 的核心思想体现在 `TimesBlock` 的构建上：先对数据做 FFT 得到基频，然后基于前 k 个主要基频，将一维时序重塑为 2D 矩阵，接着做二维卷积，最后再将输出变回一维并加权得到最终结果。\n",
    "#\n",
    " 接下来我们详细看下 `TimesBlock`。\n",
    "#\n",
    " TimesBlock 包含两个成员函数。"
   ],
   "id": "f0adb85d60a1c416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "\n"
   ],
   "id": "912fc54327e4a66c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "先看 `__init__(self, configs):`",
   "id": "843c451a218cd989"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def __init__(self, configs):  ## configs 为 TimesBlock 的配置参数\n",
    "    super(TimesBlock, self).__init__()\n",
    "    self.seq_len = configs.seq_len  ## 输入序列长度\n",
    "    self.pred_len = configs.pred_len  ## 预测序列长度\n",
    "    self.k = configs.top_k  ## top_k 表示要考虑的主要频率个数\n",
    "    # 参数高效设计：使用两层 Inception 卷积 + GELU\n",
    "    self.conv = nn.Sequential(\n",
    "        Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                           num_kernels=configs.num_kernels),\n",
    "        nn.GELU(),\n",
    "        Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                           num_kernels=configs.num_kernels)\n",
    "    )\n",
    "\n"
   ],
   "id": "d717ea863a4780d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "再看 `forward(self, x)`",
   "id": "86a6590c43535885"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def forward(self, x):\n",
    "    B, T, N = x.size()\n",
    "    # B: 批大小  T: 序列长度  N: 特征维度\n",
    "    period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "    # FFT_for_Period() 稍后给出。period_list([top_k]) 是前 k 个显著周期，\n",
    "    # period_weight([B, top_k]) 是对应的幅值权重\n",
    "\n",
    "    res = []\n",
    "    for i in range(self.k):\n",
    "        period = period_list[i]\n",
    "\n",
    "        # padding：为了构造 2D 矩阵，需保证 (seq_len + pred_len) 能被 period 整除\n",
    "        if (self.seq_len + self.pred_len) % period != 0:\n",
    "            length = (((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "            padding = torch.zeros([x.shape[0],\n",
    "                                   length - (self.seq_len + self.pred_len),\n",
    "                                   x.shape[2]]).to(x.device)\n",
    "            out = torch.cat([x, padding], dim=1)\n",
    "        else:\n",
    "            length = (self.seq_len + self.pred_len)\n",
    "            out = x\n",
    "\n",
    "        # reshape：切分并调整维度，准备做 2D 卷积\n",
    "        # 先 view 为 [B, length//period, period, N]，再 permute 到 [B, N, rows, cols]\n",
    "        out = out.reshape(B, length // period, period,\n",
    "                          N).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        # 2D 卷积，提取周期内与周期间的时序信息\n",
    "        out = self.conv(out)\n",
    "\n",
    "        # reshape 回一维，先 permute 再 reshape\n",
    "        out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "\n",
    "        # 去掉 padding 部分，加入结果列表\n",
    "        res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "    # 拼成 [B, length, N, top_k]\n",
    "    res = torch.stack(res, dim=-1)\n",
    "\n",
    "    # 自适应加权聚合\n",
    "    # softmax 得到归一化权重 [B, top_k]\n",
    "    period_weight = F.softmax(period_weight, dim=1)\n",
    "    # unsqueeze 并 repeat 到 [B, T, N, top_k]\n",
    "    period_weight = period_weight.unsqueeze(1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "    # 加权求和得到本层输出\n",
    "    res = torch.sum(res * period_weight, -1)\n",
    "\n",
    "    # 残差连接\n",
    "    res = res + x\n",
    "    return res\n",
    "\n"
   ],
   "id": "5f7d2b6512a9bc94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "上面提到的 `FFT_for_Period` 定义如下：",
   "id": "87538ed7f7ed2fb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def FFT_for_Period(x, k=2):\n",
    "    # x: [B, T, C]\n",
    "    # 计算 rFFT，得到频域表示 [B, freq, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "\n",
    "    # 假设周期特征在各批次和各通道上相对一致，先对 B,C 两维求平均，得到 [T]\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0  # 忽略直流分量\n",
    "\n",
    "    # 取前 k 大频率索引\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "\n",
    "    # detach 后转到 CPU 再转 numpy\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "\n",
    "    # 周期列表 [top_k]：原序列长度 // 对应主频索引\n",
    "    period = x.shape[1] // top_list\n",
    "\n",
    "    # 返回周期列表，以及每个 batch 上对应主频幅值 [B, top_k]\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n"
   ],
   "id": "c1ecc5dacfa01791"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "为了便于理解，下面给出示意图。\n",
    "#\n",
    "![FFT 说明示意图](./fft.png)\n",
    "#\n",
    "![2D 卷积说明示意图](./conv.png)\n"
   ],
   "id": "bab5e1bf5e16a8d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "更多细节请参阅论文（链接：https://openreview.net/pdf?id=ju_Uqw384Oq）\n",
   "id": "a9f153945ffb8fbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. TimesNet\n",
    "#\n",
    "到此，我们已经得到了擅长提取周期内与周期间信息的 `TimesBlock`，可以进一步构建多任务通用的 `TimesNet`，完成短期/长期预测、缺失值填补、分类、异常检测等任务。\n",
    "#\n",
    "接下来详细介绍 `TimesNet` 如何在各任务中发挥作用。"
   ],
   "id": "53deda434698fca6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        ...\n",
    "\n",
    "    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        ...\n",
    "\n",
    "    def imputation(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask):\n",
    "        ...\n",
    "\n",
    "    def anomaly_detection(self, x_enc):\n",
    "        ...\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        ...\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        ...\n",
    "\n"
   ],
   "id": "6f76d5801fd5dc95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "先看 `__init__(self, configs):`",
   "id": "35ad680d396a4bae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def __init__(self, configs):\n",
    "    super(Model, self).__init__()\n",
    "    # 参数初始化\n",
    "    self.configs = configs\n",
    "    self.task_name = configs.task_name\n",
    "    self.seq_len = configs.seq_len\n",
    "    self.label_len = configs.label_len\n",
    "    self.pred_len = configs.pred_len\n",
    "\n",
    "    # 主干：堆叠 e_layers 个 TimesBlock\n",
    "    self.model = nn.ModuleList([TimesBlock(configs)\n",
    "                                for _ in range(configs.e_layers)])\n",
    "\n",
    "    # embedding 与归一化\n",
    "    # enc_in: 编码器输入维度；d_model: 嵌入后的维度\n",
    "    self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                       configs.dropout)\n",
    "    self.layer = configs.e_layers  # 编码层数\n",
    "    self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "\n",
    "    # 根据任务定义不同头部\n",
    "    if self.task_name in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # 先做线性映射再投影到输出通道\n",
    "        self.predict_linear = nn.Linear(\n",
    "            self.seq_len, self.pred_len + self.seq_len)\n",
    "        self.projection = nn.Linear(\n",
    "            configs.d_model, configs.c_out, bias=True)\n",
    "    if self.task_name in ['imputation', 'anomaly_detection']:\n",
    "        self.projection = nn.Linear(\n",
    "            configs.d_model, configs.c_out, bias=True)\n",
    "    if self.task_name == 'classification':\n",
    "        self.act = F.gelu\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        self.projection = nn.Linear(\n",
    "            configs.d_model * configs.seq_len, configs.num_class)\n",
    "\n"
   ],
   "id": "d9867dab04b1818e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.1 Forecast\n",
    "#\n",
    "预测任务思路：将已知序列长度扩展为 seq_len+pred_len，总长度过 TimesBlock 提取特征后，投影到输出空间，再做去归一化得到最终结果。"
   ],
   "id": "6e38dc62aa646d0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "    # 非平稳 Transformer 的时序归一化\n",
    "    means = x_enc.mean(1, keepdim=True).detach()  # [B,1,C]\n",
    "    x_enc = x_enc - means\n",
    "    stdev = torch.sqrt(\n",
    "        torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "    x_enc /= stdev\n",
    "\n",
    "    # embedding：数值映射到 d_model 维向量\n",
    "    enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "    # 线性映射扩展到 [B, seq_len+pred_len, C]\n",
    "    enc_out = self.predict_linear(enc_out.permute(0, 2, 1)).permute(\n",
    "        0, 2, 1)\n",
    "\n",
    "    # TimesNet 主体：多层 TimesBlock + LayerNorm\n",
    "    for i in range(self.layer):\n",
    "        enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "    # 投影到输出通道 [B,T,C_out]\n",
    "    dec_out = self.projection(enc_out)\n",
    "\n",
    "    # 去归一化\n",
    "    dec_out = dec_out * \\\n",
    "              (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                  1, self.pred_len + self.seq_len, 1))\n",
    "    dec_out = dec_out + \\\n",
    "              (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                  1, self.pred_len + self.seq_len, 1))\n",
    "    return dec_out\n",
    "\n"
   ],
   "id": "ea13342f30fa456d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.2 Imputation（缺失值填补）\n",
    "#\n",
    "与预测类似，不过只在已知序列中填补缺失值。"
   ],
   "id": "8d80931cc41fc805"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def imputation(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask):\n",
    "    # 非平稳 Transformer 归一化（考虑 mask）\n",
    "    means = torch.sum(x_enc, dim=1) / torch.sum(mask == 1, dim=1)\n",
    "    means = means.unsqueeze(1).detach()\n",
    "    x_enc = x_enc - means\n",
    "    x_enc = x_enc.masked_fill(mask == 0, 0)\n",
    "    stdev = torch.sqrt(torch.sum(x_enc * x_enc, dim=1) /\n",
    "                       torch.sum(mask == 1, dim=1) + 1e-5)\n",
    "    stdev = stdev.unsqueeze(1).detach()\n",
    "    x_enc /= stdev\n",
    "\n",
    "    # embedding\n",
    "    enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "    # TimesNet\n",
    "    for i in range(self.layer):\n",
    "        enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "    # 投影\n",
    "    dec_out = self.projection(enc_out)\n",
    "\n",
    "    # 去归一化\n",
    "    dec_out = dec_out * \\\n",
    "              (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                  1, self.pred_len + self.seq_len, 1))\n",
    "    dec_out = dec_out + \\\n",
    "              (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                  1, self.pred_len + self.seq_len, 1))\n",
    "    return dec_out\n",
    "\n"
   ],
   "id": "c199d2a2b29865ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.3 异常检测\n",
    "#\n",
    "与缺失值填补类似。"
   ],
   "id": "f746d55c85d9a76e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def anomaly_detection(self, x_enc):\n",
    "    # 非平稳 Transformer 归一化\n",
    "    means = x_enc.mean(1, keepdim=True).detach()\n",
    "    x_enc = x_enc - means\n",
    "    stdev = torch.sqrt(\n",
    "        torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "    x_enc /= stdev\n",
    "    # embedding\n",
    "    enc_out = self.enc_embedding(x_enc, None)  # [B,T,C]\n",
    "    # TimesNet\n",
    "    for i in range(self.layer):\n",
    "        enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "    # 投影\n",
    "    dec_out = self.projection(enc_out)\n",
    "    # 去归一化\n",
    "    dec_out = dec_out * \\\n",
    "              (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                  1, self.pred_len + self.seq_len, 1))\n",
    "    dec_out = dec_out + \\\n",
    "              (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                  1, self.pred_len + self.seq_len, 1))\n",
    "    return dec_out\n",
    "\n"
   ],
   "id": "f78a82b07f43d900"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.4 分类",
   "id": "7777d8c95c410d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def classification(self, x_enc, x_mark_enc):\n",
    "    # embedding\n",
    "    enc_out = self.enc_embedding(x_enc, None)  # [B,T,C]\n",
    "    # TimesNet\n",
    "    for i in range(self.layer):\n",
    "        enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "    # 输出：先激活、再 dropout\n",
    "    output = self.act(enc_out)\n",
    "    output = self.dropout(output)\n",
    "\n",
    "    # 将 padding 位置的 embedding 置零，帮助模型关注有效数据\n",
    "    output = output * x_mark_enc.unsqueeze(-1)\n",
    "\n",
    "    # 展平后投影到类别数\n",
    "    output = output.reshape(output.shape[0], -1)\n",
    "    output = self.projection(output)  # [B, num_classes]\n",
    "    return output\n",
    "\n"
   ],
   "id": "d5152ecc6101c1dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`forward` 根据任务类型调用不同方法：",
   "id": "c167544bb6941a65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "    if self.task_name in ['long_term_forecast', 'short_term_forecast']:\n",
    "        dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "        return dec_out[:, -self.pred_len:, :]  # 只返回预测部分\n",
    "    if self.task_name == 'imputation':\n",
    "        dec_out = self.imputation(x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\n",
    "        return dec_out  # 返回完整序列（含填补）\n",
    "    if self.task_name == 'anomaly_detection':\n",
    "        dec_out = self.anomaly_detection(x_enc)\n",
    "        return dec_out  # 返回修正后序列\n",
    "    if self.task_name == 'classification':\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # 返回分类结果\n",
    "    return None\n",
    "\n"
   ],
   "id": "ff9ff778b004a44b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. 训练与设置\n",
    "#\n",
    "到目前为止我们已经构建好 `TimesNet`，接下来讨论如何训练和测试。`exp` 目录下聚合了各任务的训练、验证、测试逻辑。这里以长期预测任务为例说明训练流程，其它任务大同小异。\n",
    "#\n",
    "#### 5.1 长期预测任务的训练\n",
    "#\n",
    "训练过程可分为：数据准备、保存路径创建、初始化、优化器与损失函数选择、混合精度训练、训练循环、验证与早停、学习率调整、加载最佳模型等步骤。  \n",
    "以下代码节选自 `class Exp_Long_Term_Forecast` 的 `train` 方法。"
   ],
   "id": "efa922363728eb2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def train(self, setting):  # setting 是此次训练的参数配置名称\n",
    "    # 获取训练/验证/测试的数据和加载器\n",
    "    train_data, train_loader = self._get_data(flag='train')\n",
    "    vali_data, vali_loader = self._get_data(flag='val')\n",
    "    test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "    # 设置模型检查点保存路径\n",
    "    path = os.path.join(self.args.checkpoints, setting)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    time_now = time.time()\n",
    "\n",
    "    train_steps = len(train_loader)\n",
    "\n",
    "    # EarlyStopping: 根据验证损失判断是否提前停止训练\n",
    "    early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "\n",
    "    # 选择优化器和损失函数\n",
    "    model_optim = self._select_optimizer()\n",
    "    criterion = self._select_criterion()\n",
    "\n",
    "    # AMP 混合精度训练\n",
    "    if self.args.use_amp:\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(self.args.train_epochs):\n",
    "        iter_count = 0\n",
    "        train_loss = []\n",
    "        self.model.train()\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        # 开始本轮训练\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "            iter_count += 1\n",
    "            model_optim.zero_grad()\n",
    "            batch_x = batch_x.float().to(self.device)  # 输入特征\n",
    "            batch_y = batch_y.float().to(self.device)  # 目标特征\n",
    "\n",
    "            # _mark 包含时间特征信息\n",
    "            batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "            batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "            # 构造解码器输入（TimesNet 不使用 attention，所以可以全 0 拼接）\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "            # 前向与反向\n",
    "            if self.args.use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                    # MS 模式下只取最后一列\n",
    "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "            else:\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            # 每 100 步打印一次训练进度、损失、速度估计等\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                speed = (time.time() - time_now) / iter_count\n",
    "                left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                iter_count = 0\n",
    "                time_now = time.time()\n",
    "\n",
    "            # 反向传播\n",
    "            if self.args.use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(model_optim)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                model_optim.step()\n",
    "\n",
    "        # 本轮结束，打印耗时\n",
    "        print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "        train_loss = np.average(train_loss)\n",
    "\n",
    "        # 在验证集和测试集上评估\n",
    "        vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "        test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "        print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "            epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "\n",
    "        # 早停判断\n",
    "        early_stopping(vali_loss, self.model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "\n",
    "    # 加载训练得到的最佳模型\n",
    "    self.model.load_state_dict(torch.load(best_model_path))\n",
    "    return self.model\n",
    "\n"
   ],
   "id": "fa3b0f07914582c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 5.2 早停机制\n",
    "#\n",
    "`EarlyStopping` 会监控验证损失，当连续若干次验证损失不下降时停止训练，避免过拟合。以下为 `tools.py` 中的实现。"
   ],
   "id": "55f394e48b3a3572"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience  # 容忍验证损失不下降的轮数\n",
    "        self.verbose = verbose  # 是否打印信息\n",
    "        self.counter = 0  # 当前连续未下降次数\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            # 首次记录\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            # 验证损失未提升\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                # 达到容忍上限\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            # 验证损失提升，保存模型并重置计数\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        # 保存当前最佳模型\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "        self.val_loss_min = val_loss\n",
    "\n"
   ],
   "id": "cd454963a743e717"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 5.3 优化器与损失函数\n",
    "#\n",
    "在 `Exp_Long_Term_Forecast` 类中由 `_select_optimizer()` 和 `_select_criterion()` 定义。长期预测任务中使用 Adam 优化器和 MSELoss。"
   ],
   "id": "d59723bcaee4a859"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _select_optimizer(self):\n",
    "    model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "    return model_optim\n",
    "\n",
    "\n",
    "def _select_criterion(self):\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion\n",
    "\n"
   ],
   "id": "4374391ad4ca9355"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 5.4 自动混合精度（AMP）\n",
    "#\n",
    "AMP 可在保持数值稳定性的同时加速训练、节省显存。主要用到 `torch.cuda.amp.autocast()` 和 `GradScaler`。"
   ],
   "id": "afbdec7dee31c520"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 在前向过程中：\n",
    "with torch.cuda.amp.autocast():\n",
    "    ...\n",
    "\n",
    "# 在反向过程中：\n",
    "if self.args.use_amp:\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(model_optim)\n",
    "    scaler.update()\n",
    "\n"
   ],
   "id": "41dde4d472420420"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 5.5 学习率调整\n",
    "#\n",
    "手动或按规则调整学习率，见 `tools.py` 中的 `adjust_learning_rate`。"
   ],
   "id": "6d0b699310ead479"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    # 第一种：按指数衰减\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    # 第二种：手动指定轮次\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    # 按需更新\n",
    "    if epoch in lr_adjust:\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print('Updating learning rate to {}'.format(lr))\n",
    "\n"
   ],
   "id": "18f0a546b3fc6640"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. 验证与测试\n",
    "#\n",
    "验证可以评估模型的泛化能力，检测过拟合，并采用早停或调整超参等策略。下面以长期预测为例。"
   ],
   "id": "18c6f6f639769fe0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def vali(self, vali_data, vali_loader, criterion):\n",
    "    total_loss = []\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "            batch_x = batch_x.float().to(self.device)\n",
    "            batch_y = batch_y.float()\n",
    "            batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "            batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "            # 构造解码器输入\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "            if self.args.use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            else:\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "            pred = outputs.detach().cpu()\n",
    "            true = batch_y.detach().cpu()\n",
    "            loss = criterion(pred, true)\n",
    "            total_loss.append(loss)\n",
    "    total_loss = np.average(total_loss)\n",
    "    self.model.train()\n",
    "    return total_loss\n",
    "\n"
   ],
   "id": "e566fa44527c0aa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "测试过程类似验证，但通常会额外可视化结果。",
   "id": "24434fec04fbcf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visual(true, preds=None, name='./pic/test.pdf'):\n",
    "    \"\"\"\n",
    "    结果可视化\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(true, label='GroundTruth', linewidth=2)\n",
    "    if preds is not None:\n",
    "        plt.plot(preds, label='Prediction', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.savefig(name, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def test(self, setting, test=0):\n",
    "    test_data, test_loader = self._get_data(flag='test')\n",
    "    if test:\n",
    "        print('加载模型')\n",
    "        self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    folder_path = './test_results/' + setting + '/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "            batch_x = batch_x.float().to(self.device)\n",
    "            batch_y = batch_y.float().to(self.device)\n",
    "            batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "            batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "            # 构造解码器输入\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "            # 前向\n",
    "            if self.args.use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            else:\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            # 若做过归一化，反归一化\n",
    "            if test_data.scale and self.args.inverse:\n",
    "                outputs = test_data.inverse_transform(outputs)\n",
    "                batch_y = test_data.inverse_transform(batch_y)\n",
    "\n",
    "            pred = outputs\n",
    "            true = batch_y\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "\n",
    "            # 每 20 个 batch 可视化一次\n",
    "            if i % 20 == 0:\n",
    "                input = batch_x.detach().cpu().numpy()\n",
    "                gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)  # [batch_num, batch_size, pred_len, features]\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "    # 保存结果\n",
    "    folder_path = './results/' + setting + '/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "    print('mse:{}, mae:{}'.format(mse, mae))\n",
    "    with open(\"result_long_term_forecast.txt\", 'a') as f:\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f.write('\\n\\n')\n",
    "\n",
    "    np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "    np.save(folder_path + 'pred.npy', preds)\n",
    "    np.save(folder_path + 'true.npy', trues)\n",
    "\n"
   ],
   "id": "a3b3c369bf1eff37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. Dataloader 与 DataProvider\n",
    "#\n",
    "训练时通过 `self._get_data(flag)` 获取数据，下面看其实现："
   ],
   "id": "28ac2da22896344a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _get_data(self, flag):\n",
    "    data_set, data_loader = data_provider(self.args, flag)\n",
    "    return data_set, data_loader\n",
    "\n"
   ],
   "id": "f6e6e0e75605880a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`data_provider(self.args, flag)` 定义在 `data_factory.py`：",
   "id": "67167f8c26735e7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_dict = {\n",
    "    'ETTh1': Dataset_ETT_hour,\n",
    "    'ETTh2': Dataset_ETT_hour,\n",
    "    'ETTm1': Dataset_ETT_minute,\n",
    "    'ETTm2': Dataset_ETT_minute,\n",
    "    'custom': Dataset_Custom,\n",
    "    'm4': Dataset_M4,\n",
    "    'PSM': PSMSegLoader,\n",
    "    'MSL': MSLSegLoader,\n",
    "    'SMAP': SMAPSegLoader,\n",
    "    'SMD': SMDSegLoader,\n",
    "    'SWAT': SWATSegLoader,\n",
    "    'UEA': UEAloader\n",
    "}\n",
    "\n",
    "\n",
    "def data_provider(args, flag):\n",
    "    Data = data_dict[args.data]  # 根据数据名称选择 Dataset\n",
    "    timeenc = 0 if args.embed != 'timeF' else 1  # 时间特征编码方式\n",
    "\n",
    "    if flag == 'test':\n",
    "        shuffle_flag = False\n",
    "        drop_last = True\n",
    "        # 异常检测 / 分类任务测试时可批量处理\n",
    "        if args.task_name in ['anomaly_detection', 'classification']:\n",
    "            batch_size = args.batch_size\n",
    "        else:\n",
    "            batch_size = 1  # 评估阶段 bsz=1\n",
    "        freq = args.freq\n",
    "    else:\n",
    "        shuffle_flag = True\n",
    "        drop_last = True\n",
    "        batch_size = args.batch_size  # 训练/验证批大小\n",
    "        freq = args.freq\n",
    "\n",
    "    if args.task_name == 'anomaly_detection':\n",
    "        drop_last = False\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,  # 数据文件根路径\n",
    "            win_size=args.seq_len,  # 输入序列长度\n",
    "            flag=flag,\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    elif args.task_name == 'classification':\n",
    "        drop_last = False\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,\n",
    "            flag=flag,\n",
    "        )\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last,\n",
    "            collate_fn=lambda x: collate_fn(x, max_len=args.seq_len)\n",
    "        )\n",
    "        return data_set, data_loader\n",
    "    else:\n",
    "        if args.data == 'm4':\n",
    "            drop_last = False\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,  # 如 ./data/ETT/\n",
    "            data_path=args.data_path,  # 如 ETTh1.csv\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,  # 预测模式：M/S/MS\n",
    "            target=args.target,  # S 或 MS 任务下的目标列\n",
    "            timeenc=timeenc,\n",
    "            freq=freq,\n",
    "            seasonal_patterns=args.seasonal_patterns\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "        return data_set, data_loader\n",
    "\n"
   ],
   "id": "e98ddb8ff8d3d8f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "上述 `data_provider` 根据任务和模式，将原始数据集封装为可迭代的 DataLoader。  \n",
    "接下来示例 `data_loader.py` 中的 `Dataset_ETT_hour`："
   ],
   "id": "304ba09187550706"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Dataset_ETT_hour(Dataset):\n",
    "    def __init__(self, root_path, flag='train', size=None,\n",
    "                 features='S', data_path='ETTh1.csv',\n",
    "                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n",
    "        ...\n",
    "\n",
    "    def __read_data__(self):\n",
    "        ...\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ...\n",
    "\n",
    "    def __len__(self):\n",
    "        ...\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        ...\n",
    "\n"
   ],
   "id": "287edf2c3eb93cce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`__init__()` 初始化各参数并调用 `__read_data__()` 加载数据。",
   "id": "d4f8d4f417c8bf3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def __init__(self, root_path, flag='train', size=None,\n",
    "             features='S', data_path='ETTh1.csv',\n",
    "             target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n",
    "    # size = [seq_len, label_len, pred_len]\n",
    "    if size is None:\n",
    "        self.seq_len = 24 * 4 * 4\n",
    "        self.label_len = 24 * 4\n",
    "        self.pred_len = 24 * 4\n",
    "    else:\n",
    "        self.seq_len, self.label_len, self.pred_len = size\n",
    "    assert flag in ['train', 'test', 'val']\n",
    "    type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "    self.set_type = type_map[flag]\n",
    "    self.features = features\n",
    "    self.target = target\n",
    "    self.scale = scale\n",
    "    self.timeenc = timeenc\n",
    "    self.freq = freq\n",
    "    self.root_path = root_path\n",
    "    self.data_path = data_path\n",
    "\n",
    "    # 调用数据读取方法\n",
    "    self.__read_data__()\n",
    "\n"
   ],
   "id": "b2b12ceba384e76a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`__read_data__()` 将原始 CSV 划分为训练/验证/测试集，筛选列并做归一化和时间特征编码。\n",
    ">>\n",
    "def __read_data__(self):\n",
    "    self.scaler = StandardScaler()\n",
    "\n",
    "    # 从文件读取原始数据\n",
    "    df_raw = pd.read_csv(os.path.join(self.root_path, self.data_path))\n",
    "\n",
    "    # 定义各集边界\n",
    "    border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
    "    border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
    "    border1 = border1s[self.set_type]\n",
    "    border2 = border2s[self.set_type]\n",
    "\n",
    "    # 选择特征列\n",
    "    if self.features in ['M', 'MS']:\n",
    "        cols_data = df_raw.columns[1:]  # 去除日期列\n",
    "        df_data = df_raw[cols_data]\n",
    "    elif self.features == 'S':\n",
    "        df_data = df_raw[[self.target]]\n",
    "\n",
    "    # 归一化\n",
    "    if self.scale:\n",
    "        train_data = df_data[border1s[0]:border2s[0]]\n",
    "        self.scaler.fit(train_data.values)\n",
    "        data = self.scaler.transform(df_data.values)\n",
    "    else:\n",
    "        data = df_data.values\n",
    "\n",
    "        # 提取时间戳\n",
    "    df_stamp = df_raw[['date']][border1:border2]\n",
    "    df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "\n",
    "    if self.timeenc == 0:\n",
    "        # 固定时间特征：月、日、周、时\n",
    "        df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "        df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "        df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "        df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "        data_stamp = df_stamp.drop(['date'], axis=1).values\n",
    "    elif self.timeenc == 1:\n",
    "        # timeF 编码：按 freq 生成归一化时间特征\n",
    "        data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "        data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "    # 保存处理后数据\n",
    "    self.data_x = data[border1:border2]\n",
    "    self.data_y = data[border1:border2]\n",
    "    self.data_stamp = data_stamp\n",
    "\n"
   ],
   "id": "e66f5978936549fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "实现 `__getitem__` 与 `__len__`\n",
    ">>\n",
    "def __getitem__(self, index):\n",
    "    # 计算输入、输出区间\n",
    "    s_begin = index\n",
    "    s_end = s_begin + self.seq_len\n",
    "    r_begin = s_end - self.label_len\n",
    "    r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "    # 切分序列和时间标记\n",
    "    seq_x = self.data_x[s_begin:s_end]\n",
    "    seq_y = self.data_y[r_begin:r_end]\n",
    "    seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "    seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "    return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "\n",
    "def __len__(self):\n",
    "    return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n"
   ],
   "id": "c01c423742edec24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "若需反归一化，可调用：\n",
    ">>\n",
    "def inverse_transform(self, data):\n",
    "    return self.scaler.inverse_transform(data)\n",
    "\n"
   ],
   "id": "fd283d4ef92e9b67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "至此完成数据集与 DataLoader 的构建。下面展示一些常用数据集示例图。\n",
    "#\n",
    "![常用时序数据集](./dataset.png)\n"
   ],
   "id": "c10aacadb3cff5be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 8. 运行实验与可视化结果\n",
    "#\n",
    "构建好数据和模型后，在 shell 脚本中运行 `run.py` 并传入参数。以下以 ETTh1 数据集的长期预测为例。\n",
    ">>\n",
    "model_name = TimesNet\n",
    "\n",
    "python - u\n",
    "run.py \\\n",
    "- -task_name\n",
    "long_term_forecast \\\n",
    "- -is_training\n",
    "1 \\\n",
    "- -root_path. / dataset / ETT - small / \\\n",
    "--data_path\n",
    "ETTh1.csv \\\n",
    "- -model_id\n",
    "ETTh1_96_96 \\\n",
    "- -model $model_name \\\n",
    "          - -data\n",
    "ETTh1 \\\n",
    "- -features\n",
    "M \\\n",
    "- -seq_len\n",
    "96 \\\n",
    "- -label_len\n",
    "48 \\\n",
    "- -pred_len\n",
    "96 \\\n",
    "- -e_layers\n",
    "2 \\\n",
    "- -d_layers\n",
    "1 \\\n",
    "- -factor\n",
    "3 \\\n",
    "- -enc_in\n",
    "7 \\\n",
    "- -dec_in\n",
    "7 \\\n",
    "- -c_out\n",
    "7 \\\n",
    "- -d_model\n",
    "16 \\\n",
    "- -d_ff\n",
    "32 \\\n",
    "- -des\n",
    "'Exp' \\\n",
    "- -itr\n",
    "1 \\\n",
    "- -top_k\n",
    "5\n"
   ],
   "id": "70753b80ffd371a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "完成脚本后可通过 bash 运行，例如：\n",
    ">>\n",
    "bash. / scripts / long_term_forecast / ETT_script / TimesNet_ETTh1.sh\n"
   ],
   "id": "7c0a8756cf023e4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "运行成功的标志：看到类似以下输出：\n",
    ">>\n",
    "Namespace(task_name='long_term_forecast', is_training=1, model_id='ETTh1_96_96', model='TimesNet', data='ETTh1',\n",
    "          root_path='./dataset/ETT-small/', data_path='ETTh1.csv', features='M', target='OT', freq='h',\n",
    "          checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, seasonal_patterns='Monthly',\n",
    "          inverse=False, mask_rate=0.25, anomaly_ratio=0.25, top_k=5, num_kernels=6, enc_in=7, dec_in=7, c_out=7,\n",
    "          d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=32, moving_avg=25, factor=3, distil=True, dropout=0.1,\n",
    "          embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=1, train_epochs=10,\n",
    "          batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False,\n",
    "          use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2)\n",
    "Use\n",
    "GPU: cuda:0\n",
    ">> >> >> > start\n",
    "training: long_term_forecast_ETTh1_96_96_TimesNet_ETTh1_ftM_sl96_ll48_pl96_dm16_nh8_el2_dl1_df32_fc3_ebtimeF_dtTrue_Exp_0 >> >> >> >> >> >> >> >> >> >> >> >> >>\n",
    "train\n",
    "8449\n",
    "val\n",
    "2785\n",
    "test\n",
    "2785\n"
   ],
   "id": "b324966ac2f9f6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "训练过程中每轮结束时会打印：\n",
    ">>\n",
    "iters: 100, epoch: 1 | loss: 0.4701951\n",
    "speed: 0.2108\n",
    "s / iter;\n",
    "left\n",
    "time: 535.7317\n",
    "s\n",
    "iters: 200, epoch: 1 | loss: 0.4496171\n",
    "speed: 0.0615\n",
    "s / iter;\n",
    "left\n",
    "time: 150.0223\n",
    "s\n",
    "Epoch: 1\n",
    "cost\n",
    "time: 30.09317970275879\n",
    "Epoch: 1, Steps: 264 | Train\n",
    "Loss: 0.4964185\n",
    "Vali\n",
    "Loss: 0.8412074\n",
    "Test\n",
    "Loss: 0.4290483\n",
    "Validation\n",
    "loss\n",
    "decreased(inf --> 0.841207).Saving\n",
    "model...\n",
    "Updating\n",
    "learning\n",
    "rate\n",
    "to\n",
    "0.0001\n"
   ],
   "id": "47962d6705335523"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "全部训练结束后进入测试，会打印 MAE 和 MSE：\n",
    ">>\n",
    ">> >> >> > testing: long_term_forecast_ETTh1_96_96_TimesNet_ETTh1_ftM_sl96_ll48_pl96_dm16_nh8_el2_dl1_df32_fc3_ebtimeF_dtTrue_Exp_0 << << << << << << << << << << << << << << << << <\n",
    "test\n",
    "2785\n",
    "test\n",
    "shape: (2785, 1, 96, 7)(2785, 1, 96, 7)\n",
    "test\n",
    "shape: (2785, 96, 7)(2785, 96, 7)\n",
    "mse: 0.3890332877635956, mae: 0.41201362013816833\n"
   ],
   "id": "9d7a3f7ce931f1c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "测试结果（PDF 格式）保存在 `test_results` 文件夹中，例如：\n",
    "#\n",
    "![ETTm1 2440 结果示例](./result.png)\n"
   ],
   "id": "a1286875ec6e72de"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
